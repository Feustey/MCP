"""
Endpoint intelligent pour chatbot dazno.de
R√©pond aux questions selon le contexte du n≈ìud Lightning fourni
"""

from fastapi import APIRouter, HTTPException, Depends, Body
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, List
import logging
from datetime import datetime

from app.services.auth import verify_api_key
from src.lightning.max_flow_analysis import LightningMaxFlowAnalyzer
from src.lightning.graph_theory_metrics import LightningGraphAnalyzer
from src.lightning.financial_analysis import LightningFinancialAnalyzer
from src.clients.anthropic_client import AnthropicClient

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/chatbot", tags=["Chatbot Intelligence"])

class ChatbotQuery(BaseModel):
    """Mod√®le pour les requ√™tes du chatbot"""
    message: str = Field(..., description="Question/message de l'utilisateur")
    node_pubkey: Optional[str] = Field(None, description="Public key du n≈ìud Lightning (optionnel)")
    context: Optional[Dict[str, Any]] = Field(None, description="Contexte additionnel")
    conversation_id: Optional[str] = Field(None, description="ID de conversation pour le suivi")

class ChatbotResponse(BaseModel):
    """Mod√®le de r√©ponse du chatbot"""
    response: str = Field(..., description="R√©ponse intelligente du chatbot")
    node_analysis: Optional[Dict[str, Any]] = Field(None, description="Analyse du n≈ìud si applicable")
    suggestions: Optional[List[str]] = Field(None, description="Suggestions d'actions")
    confidence: float = Field(..., description="Niveau de confiance de la r√©ponse (0-1)")
    response_type: str = Field(..., description="Type de r√©ponse: general, node_specific, analysis, error")

class ChatbotIntelligence:
    """Classe principale pour l'intelligence du chatbot"""
    
    def __init__(self):
        self.anthropic = AnthropicClient()
        self.max_flow_analyzer = LightningMaxFlowAnalyzer()
        self.graph_analyzer = LightningGraphAnalyzer()
        self.financial_analyzer = LightningFinancialAnalyzer()
        
    async def analyze_node_context(self, node_pubkey: str) -> Dict[str, Any]:
        """Analyse le contexte d'un n≈ìud pour enrichir la conversation"""
        try:
            # Analyses parall√®les du n≈ìud
            node_data = {}
            
            # Analyse de centralit√©
            try:
                centrality = await self.graph_analyzer.calculate_centrality_metrics(node_pubkey)
                node_data["centrality"] = centrality
            except Exception as e:
                logger.warning(f"Erreur analyse centralit√©: {e}")
                
            # Analyse financi√®re
            try:
                financial = await self.financial_analyzer.analyze_node_financials(
                    node_pubkey, [], []
                )
                node_data["financial"] = financial
            except Exception as e:
                logger.warning(f"Erreur analyse financi√®re: {e}")
                
            # Donn√©es de base du n≈ìud
            node_data.update({
                "pubkey": node_pubkey,
                "alias": self._get_node_alias(node_pubkey),
                "analyzed_at": datetime.utcnow().isoformat(),
                "analysis_quality": "complete" if len(node_data) > 2 else "partial"
            })
            
            return node_data
            
        except Exception as e:
            logger.error(f"Erreur analyse contexte n≈ìud {node_pubkey}: {e}")
            return {"pubkey": node_pubkey, "error": str(e)}
    
    def _get_node_alias(self, node_pubkey: str) -> str:
        """Obtient l'alias d'un n≈ìud (simplifi√© pour l'exemple)"""
        # Mapping de quelques n≈ìuds connus
        known_nodes = {
            "02b1fe652cfc61f1e5cef78c08d60918d9fad3f029808f995a959e0a9dcbd33bab": "barcelona-big",
            # Ajouter d'autres n≈ìuds connus...
        }
        return known_nodes.get(node_pubkey, f"Node-{node_pubkey[:8]}...")
    
    async def generate_intelligent_response(
        self, 
        message: str, 
        node_data: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> ChatbotResponse:
        """G√©n√®re une r√©ponse intelligente bas√©e sur le contexte"""
        
        try:
            # Construire le prompt pour Claude
            system_prompt = self._build_system_prompt(node_data)
            user_prompt = self._build_user_prompt(message, node_data, context)
            
            # Appel √† Claude/Anthropic
            claude_response = await self.anthropic.generate_completion(
                messages=[{"role": "user", "content": user_prompt}],
                system_message=system_prompt,
                max_tokens=1000
            )
            
            # Analyser et structurer la r√©ponse
            response_data = self._parse_claude_response(claude_response, node_data)
            
            return ChatbotResponse(**response_data)
            
        except Exception as e:
            logger.error(f"Erreur g√©n√©ration r√©ponse: {e}")
            return ChatbotResponse(
                response=f"D√©sol√©, j'ai rencontr√© une erreur: {str(e)}",
                confidence=0.1,
                response_type="error"
            )
    
    def _build_system_prompt(self, node_data: Optional[Dict[str, Any]]) -> str:
        """Construit le prompt syst√®me pour Claude"""
        base_prompt = """Tu es un assistant expert Lightning Network pour le site dazno.de. 
        Tu aides les utilisateurs √† comprendre et optimiser leurs n≈ìuds Lightning.
        
        Tes sp√©cialit√©s:
        - Analyse de performance des n≈ìuds Lightning
        - Optimisation des frais et de la liquidit√©
        - Conseils strat√©giques pour le routage
        - Diagnostic de probl√®mes de connexions
        - Analyse de centralit√© et positionnement r√©seau
        
        R√©ponds de mani√®re concise, professionnelle et actionnable.
        Utilise des donn√©es concr√®tes quand disponibles."""
        
        if node_data:
            node_prompt = f"""
            
        CONTEXTE DU N≈íUD ACTUEL:
        - Alias: {node_data.get('alias', 'Inconnu')}
        - PubKey: {node_data.get('pubkey', 'Non sp√©cifi√©')[:16]}...
        """
            
            if node_data.get('centrality'):
                cent = node_data['centrality']
                node_prompt += f"""
        - Centralit√© degr√©: {cent.get('degree_centrality', 0):.3f}
        - Centralit√© interm√©diaire: {cent.get('betweenness_centrality', 0):.3f}
        - Position r√©seau: {"Hub important" if cent.get('degree_centrality', 0) > 0.1 else "N≈ìud standard"}
        """
                
            if node_data.get('financial'):
                fin = node_data['financial']
                node_prompt += f"""
        - ROI annuel estim√©: {fin.get('annual_roi_percent', 0):.2f}%
        - Revenus estim√©s: {fin.get('total_fees_earned', 0)} sats
        """
                
            base_prompt += node_prompt
            
        return base_prompt
    
    def _build_user_prompt(
        self, 
        message: str, 
        node_data: Optional[Dict[str, Any]], 
        context: Optional[Dict[str, Any]]
    ) -> str:
        """Construit le prompt utilisateur"""
        prompt = f"Question de l'utilisateur: {message}"
        
        if context:
            prompt += f"\n\nContexte additionnel: {context}"
            
        prompt += "\n\nR√©ponds de mani√®re utile et sp√©cifique au contexte Lightning Network."
        
        return prompt
    
    def _parse_claude_response(
        self, 
        claude_response: str, 
        node_data: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Parse et structure la r√©ponse de Claude"""
        
        # D√©terminer le type de r√©ponse
        response_type = "general"
        if node_data:
            response_type = "node_specific"
            
        # G√©n√©rer des suggestions bas√©es sur le contexte
        suggestions = self._generate_suggestions(claude_response, node_data)
        
        # Calculer la confiance (simplifi√©)
        confidence = 0.8 if node_data else 0.6
        
        return {
            "response": claude_response,
            "node_analysis": node_data,
            "suggestions": suggestions,
            "confidence": confidence,
            "response_type": response_type
        }
    
    def _generate_suggestions(
        self, 
        response: str, 
        node_data: Optional[Dict[str, Any]]
    ) -> List[str]:
        """G√©n√®re des suggestions d'actions"""
        suggestions = []
        
        if node_data:
            # Suggestions bas√©es sur les m√©triques du n≈ìud
            centrality = node_data.get('centrality', {})
            financial = node_data.get('financial', {})
            
            if centrality.get('degree_centrality', 0) < 0.05:
                suggestions.append("Consid√©rez ouvrir plus de canaux pour am√©liorer votre centralit√©")
                
            if financial.get('annual_roi_percent', 0) < 5:
                suggestions.append("Analysez vos frais - ils pourraient √™tre optimis√©s")
                
            suggestions.append("Consultez l'analyse compl√®te de votre n≈ìud")
            
        else:
            # Suggestions g√©n√©rales
            suggestions.extend([
                "Sp√©cifiez votre n≈ìud pour une analyse personnalis√©e",
                "Explorez les m√©triques de performance disponibles"
            ])
            
        return suggestions[:3]  # Limiter √† 3 suggestions

# Instance globale
chatbot_intelligence = ChatbotIntelligence()

@router.post("/ask",
    summary="Chatbot Intelligent Lightning Network",
    description="Assistant IA pour optimisation et diagnostic de n≈ìuds Lightning avec analyse contextuelle",
    response_model=ChatbotResponse,
    responses={
        200: {
            "description": "R√©ponse intelligente g√©n√©r√©e avec succ√®s",
            "content": {
                "application/json": {
                    "example": {
                        "response": "Votre n≈ìud montre une bonne centralit√© (0.082) mais votre ROI annuel de 3.2% pourrait √™tre am√©lior√© en ajustant vos frais...",
                        "node_analysis": {
                            "alias": "barcelona-big",
                            "centrality": {"degree_centrality": 0.082, "betweenness_centrality": 0.045},
                            "financial": {"annual_roi_percent": 3.2, "total_fees_earned": 125000}
                        },
                        "suggestions": [
                            "Consid√©rez augmenter vos frais de base de 10-15%",
                            "Ouvrez 2-3 canaux avec des hubs majeurs",
                            "Analysez vos canaux inactifs pour r√©√©quilibrage"
                        ],
                        "confidence": 0.85,
                        "response_type": "node_specific"
                    }
                }
            }
        },
        400: {"description": "Requ√™te invalide"},
        500: {"description": "Erreur serveur"}
    }
)
async def ask_chatbot(
    query: ChatbotQuery = Body(...),
    api_key: str = Depends(verify_api_key)
):
    """
    **ü§ñ Chatbot Intelligent Lightning Network**

    Assistant IA avanc√© qui analyse votre n≈ìud Lightning et fournit
    des recommandations personnalis√©es bas√©es sur vos m√©triques r√©elles.

    **Fonctionnalit√©s Principales:**
    - üìä **Analyse Contextuelle**: √âvalue automatiquement votre n≈ìud (centralit√©, performance, finances)
    - üí° **R√©ponses Personnalis√©es**: Conseils adapt√©s √† votre configuration sp√©cifique
    - üéØ **Suggestions Actionnables**: Actions concr√®tes pour optimiser votre n≈ìud
    - üí¨ **Conversations Suivies**: Maintient le contexte pour discussions approfondies

    **M√©triques Analys√©es:**
    - Centralit√© r√©seau (degr√©, interm√©diarit√©)
    - Performance financi√®re (ROI, revenus)
    - Efficacit√© de routage
    - √âtat des canaux et liquidit√©

    **Exemples de Questions:**
    - "Comment am√©liorer la performance de mon n≈ìud ?"
    - "Mes frais sont-ils optimaux pour maximiser les revenus ?"
    - "Pourquoi ai-je peu de routage malgr√© ma bonne connectivit√© ?"
    - "Quels canaux devrais-je ouvrir pour am√©liorer ma centralit√© ?"
    - "Comment optimiser ma liquidit√© pour des paiements de 100K sats ?"

    **Param√®tres:**
    - `message`: Votre question ou demande
    - `node_pubkey`: (Optionnel) Public key de votre n≈ìud pour analyse contextuelle
    - `context`: (Optionnel) Informations additionnelles
    - `conversation_id`: (Optionnel) ID pour suivi de conversation

    **Authentification:** Requiert une API key valide (header `X-API-Key`)
    """
    
    try:
        logger.info(f"Requ√™te chatbot: {query.message[:50]}... Node: {query.node_pubkey or 'None'}")
        
        # Analyser le n≈ìud si fourni
        node_data = None
        if query.node_pubkey:
            try:
                node_data = await chatbot_intelligence.analyze_node_context(query.node_pubkey)
            except Exception as e:
                logger.warning(f"Impossible d'analyser le n≈ìud {query.node_pubkey}: {e}")
        
        # G√©n√©rer la r√©ponse intelligente
        response = await chatbot_intelligence.generate_intelligent_response(
            message=query.message,
            node_data=node_data,
            context=query.context
        )
        
        logger.info(f"R√©ponse g√©n√©r√©e avec confiance: {response.confidence}")
        return response
        
    except Exception as e:
        logger.error(f"Erreur endpoint chatbot: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Erreur lors de la g√©n√©ration de la r√©ponse: {str(e)}"
        )

@router.get("/node-summary/{node_pubkey}",
    summary="R√©sum√© rapide d'un n≈ìud",
    description="R√©sum√© contextuel d'un n≈ìud pour le chatbot",
    response_model=Dict[str, Any]
)
async def get_node_summary(
    node_pubkey: str,
    api_key: str = Depends(verify_api_key)
):
    """
    **R√©sum√© rapide d'un n≈ìud pour le chatbot**
    
    Fournit un aper√ßu rapide des m√©triques cl√©s d'un n≈ìud
    pour alimenter les conversations du chatbot.
    """
    
    try:
        node_data = await chatbot_intelligence.analyze_node_context(node_pubkey)
        
        # Simplifier pour un r√©sum√© rapide
        summary = {
            "alias": node_data.get("alias"),
            "pubkey_short": node_pubkey[:16] + "...",
            "performance_score": 0,  # √Ä calculer
            "key_metrics": {},
            "status": "analyzed" if not node_data.get("error") else "error"
        }
        
        if node_data.get("centrality"):
            cent = node_data["centrality"]
            summary["key_metrics"]["centrality"] = {
                "degree": round(cent.get("degree_centrality", 0), 3),
                "position": "hub" if cent.get("degree_centrality", 0) > 0.1 else "standard"
            }
            summary["performance_score"] += 30
            
        if node_data.get("financial"):
            fin = node_data["financial"]
            summary["key_metrics"]["financial"] = {
                "roi_annual": round(fin.get("annual_roi_percent", 0), 2),
                "profitability": "good" if fin.get("annual_roi_percent", 0) > 5 else "moderate"
            }
            summary["performance_score"] += 40
        
        return summary
        
    except Exception as e:
        logger.error(f"Erreur r√©sum√© n≈ìud {node_pubkey}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/conversation/context",
    summary="Contexte de conversation",
    description="Maintient le contexte d'une conversation chatbot"
)
async def update_conversation_context(
    conversation_id: str,
    context: Dict[str, Any] = Body(...),
    api_key: str = Depends(verify_api_key)
):
    """
    **Gestion du contexte conversationnel**
    
    Permet de maintenir le contexte d'une conversation
    pour des r√©ponses plus coh√©rentes.
    """
    
    # Pour l'instant, simple stockage en m√©moire
    # En production, utiliser Redis ou une base de donn√©es
    
    return {
        "conversation_id": conversation_id,
        "context_updated": True,
        "timestamp": datetime.utcnow().isoformat()
    }

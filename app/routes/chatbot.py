"""
Endpoint intelligent pour chatbot dazno.de
Répond aux questions selon le contexte du nœud Lightning fourni
"""

from fastapi import APIRouter, HTTPException, Depends, Body
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, List
import logging
from datetime import datetime

from app.auth import verify_api_key
from src.lightning.max_flow_analysis import LightningMaxFlowAnalyzer
from src.lightning.graph_theory_metrics import LightningGraphAnalyzer
from src.lightning.financial_analysis import LightningFinancialAnalyzer
from src.clients.anthropic_client import AnthropicClient

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/chatbot", tags=["Chatbot Intelligence"])

class ChatbotQuery(BaseModel):
    """Modèle pour les requêtes du chatbot"""
    message: str = Field(..., description="Question/message de l'utilisateur")
    node_pubkey: Optional[str] = Field(None, description="Public key du nœud Lightning (optionnel)")
    context: Optional[Dict[str, Any]] = Field(None, description="Contexte additionnel")
    conversation_id: Optional[str] = Field(None, description="ID de conversation pour le suivi")

class ChatbotResponse(BaseModel):
    """Modèle de réponse du chatbot"""
    response: str = Field(..., description="Réponse intelligente du chatbot")
    node_analysis: Optional[Dict[str, Any]] = Field(None, description="Analyse du nœud si applicable")
    suggestions: Optional[List[str]] = Field(None, description="Suggestions d'actions")
    confidence: float = Field(..., description="Niveau de confiance de la réponse (0-1)")
    response_type: str = Field(..., description="Type de réponse: general, node_specific, analysis, error")

class ChatbotIntelligence:
    """Classe principale pour l'intelligence du chatbot"""
    
    def __init__(self):
        self.anthropic = AnthropicClient()
        self.max_flow_analyzer = LightningMaxFlowAnalyzer()
        self.graph_analyzer = LightningGraphAnalyzer()
        self.financial_analyzer = LightningFinancialAnalyzer()
        
    async def analyze_node_context(self, node_pubkey: str) -> Dict[str, Any]:
        """Analyse le contexte d'un nœud pour enrichir la conversation"""
        try:
            # Analyses parallèles du nœud
            node_data = {}
            
            # Analyse de centralité
            try:
                centrality = await self.graph_analyzer.calculate_centrality_metrics(node_pubkey)
                node_data["centrality"] = centrality
            except Exception as e:
                logger.warning(f"Erreur analyse centralité: {e}")
                
            # Analyse financière
            try:
                financial = await self.financial_analyzer.analyze_node_financials(
                    node_pubkey, [], []
                )
                node_data["financial"] = financial
            except Exception as e:
                logger.warning(f"Erreur analyse financière: {e}")
                
            # Données de base du nœud
            node_data.update({
                "pubkey": node_pubkey,
                "alias": self._get_node_alias(node_pubkey),
                "analyzed_at": datetime.utcnow().isoformat(),
                "analysis_quality": "complete" if len(node_data) > 2 else "partial"
            })
            
            return node_data
            
        except Exception as e:
            logger.error(f"Erreur analyse contexte nœud {node_pubkey}: {e}")
            return {"pubkey": node_pubkey, "error": str(e)}
    
    def _get_node_alias(self, node_pubkey: str) -> str:
        """Obtient l'alias d'un nœud (simplifié pour l'exemple)"""
        # Mapping de quelques nœuds connus
        known_nodes = {
            "02b1fe652cfc61f1e5cef78c08d60918d9fad3f029808f995a959e0a9dcbd33bab": "barcelona-big",
            # Ajouter d'autres nœuds connus...
        }
        return known_nodes.get(node_pubkey, f"Node-{node_pubkey[:8]}...")
    
    async def generate_intelligent_response(
        self, 
        message: str, 
        node_data: Optional[Dict[str, Any]] = None,
        context: Optional[Dict[str, Any]] = None
    ) -> ChatbotResponse:
        """Génère une réponse intelligente basée sur le contexte"""
        
        try:
            # Construire le prompt pour Claude
            system_prompt = self._build_system_prompt(node_data)
            user_prompt = self._build_user_prompt(message, node_data, context)
            
            # Appel à Claude/Anthropic
            claude_response = await self.anthropic.generate_completion(
                messages=[{"role": "user", "content": user_prompt}],
                system_message=system_prompt,
                max_tokens=1000
            )
            
            # Analyser et structurer la réponse
            response_data = self._parse_claude_response(claude_response, node_data)
            
            return ChatbotResponse(**response_data)
            
        except Exception as e:
            logger.error(f"Erreur génération réponse: {e}")
            return ChatbotResponse(
                response=f"Désolé, j'ai rencontré une erreur: {str(e)}",
                confidence=0.1,
                response_type="error"
            )
    
    def _build_system_prompt(self, node_data: Optional[Dict[str, Any]]) -> str:
        """Construit le prompt système pour Claude"""
        base_prompt = """Tu es un assistant expert Lightning Network pour le site dazno.de. 
        Tu aides les utilisateurs à comprendre et optimiser leurs nœuds Lightning.
        
        Tes spécialités:
        - Analyse de performance des nœuds Lightning
        - Optimisation des frais et de la liquidité
        - Conseils stratégiques pour le routage
        - Diagnostic de problèmes de connexions
        - Analyse de centralité et positionnement réseau
        
        Réponds de manière concise, professionnelle et actionnable.
        Utilise des données concrètes quand disponibles."""
        
        if node_data:
            node_prompt = f"""
            
        CONTEXTE DU NŒUD ACTUEL:
        - Alias: {node_data.get('alias', 'Inconnu')}
        - PubKey: {node_data.get('pubkey', 'Non spécifié')[:16]}...
        """
            
            if node_data.get('centrality'):
                cent = node_data['centrality']
                node_prompt += f"""
        - Centralité degré: {cent.get('degree_centrality', 0):.3f}
        - Centralité intermédiaire: {cent.get('betweenness_centrality', 0):.3f}
        - Position réseau: {"Hub important" if cent.get('degree_centrality', 0) > 0.1 else "Nœud standard"}
        """
                
            if node_data.get('financial'):
                fin = node_data['financial']
                node_prompt += f"""
        - ROI annuel estimé: {fin.get('annual_roi_percent', 0):.2f}%
        - Revenus estimés: {fin.get('total_fees_earned', 0)} sats
        """
                
            base_prompt += node_prompt
            
        return base_prompt
    
    def _build_user_prompt(
        self, 
        message: str, 
        node_data: Optional[Dict[str, Any]], 
        context: Optional[Dict[str, Any]]
    ) -> str:
        """Construit le prompt utilisateur"""
        prompt = f"Question de l'utilisateur: {message}"
        
        if context:
            prompt += f"\n\nContexte additionnel: {context}"
            
        prompt += "\n\nRéponds de manière utile et spécifique au contexte Lightning Network."
        
        return prompt
    
    def _parse_claude_response(
        self, 
        claude_response: str, 
        node_data: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Parse et structure la réponse de Claude"""
        
        # Déterminer le type de réponse
        response_type = "general"
        if node_data:
            response_type = "node_specific"
            
        # Générer des suggestions basées sur le contexte
        suggestions = self._generate_suggestions(claude_response, node_data)
        
        # Calculer la confiance (simplifié)
        confidence = 0.8 if node_data else 0.6
        
        return {
            "response": claude_response,
            "node_analysis": node_data,
            "suggestions": suggestions,
            "confidence": confidence,
            "response_type": response_type
        }
    
    def _generate_suggestions(
        self, 
        response: str, 
        node_data: Optional[Dict[str, Any]]
    ) -> List[str]:
        """Génère des suggestions d'actions"""
        suggestions = []
        
        if node_data:
            # Suggestions basées sur les métriques du nœud
            centrality = node_data.get('centrality', {})
            financial = node_data.get('financial', {})
            
            if centrality.get('degree_centrality', 0) < 0.05:
                suggestions.append("Considérez ouvrir plus de canaux pour améliorer votre centralité")
                
            if financial.get('annual_roi_percent', 0) < 5:
                suggestions.append("Analysez vos frais - ils pourraient être optimisés")
                
            suggestions.append("Consultez l'analyse complète de votre nœud")
            
        else:
            # Suggestions générales
            suggestions.extend([
                "Spécifiez votre nœud pour une analyse personnalisée",
                "Explorez les métriques de performance disponibles"
            ])
            
        return suggestions[:3]  # Limiter à 3 suggestions

# Instance globale
chatbot_intelligence = ChatbotIntelligence()

@router.post("/ask", 
    summary="Chatbot intelligent Lightning Network",
    description="Endpoint pour le chatbot du site dazno.de avec analyse contextuelle des nœuds",
    response_model=ChatbotResponse,
    responses={
        200: {"description": "Réponse intelligente générée avec succès"},
        400: {"description": "Requête invalide"},
        500: {"description": "Erreur serveur"}
    }
)
async def ask_chatbot(
    query: ChatbotQuery = Body(...),
    api_key: str = Depends(verify_api_key)
):
    """
    **Chatbot intelligent pour dazno.de**
    
    Répond aux questions des utilisateurs en analysant leur nœud Lightning s'il est fourni.
    
    **Fonctionnalités:**
    - Analyse contextuelle du nœud (centralité, finances, performance)
    - Réponses personnalisées selon les métriques du nœud
    - Suggestions d'actions concrètes
    - Support des conversations suivies
    
    **Exemples d'usage:**
    - "Comment améliorer la performance de mon nœud ?"
    - "Mes frais sont-ils optimaux ?"
    - "Pourquoi ai-je peu de routage ?"
    """
    
    try:
        logger.info(f"Requête chatbot: {query.message[:50]}... Node: {query.node_pubkey or 'None'}")
        
        # Analyser le nœud si fourni
        node_data = None
        if query.node_pubkey:
            try:
                node_data = await chatbot_intelligence.analyze_node_context(query.node_pubkey)
            except Exception as e:
                logger.warning(f"Impossible d'analyser le nœud {query.node_pubkey}: {e}")
        
        # Générer la réponse intelligente
        response = await chatbot_intelligence.generate_intelligent_response(
            message=query.message,
            node_data=node_data,
            context=query.context
        )
        
        logger.info(f"Réponse générée avec confiance: {response.confidence}")
        return response
        
    except Exception as e:
        logger.error(f"Erreur endpoint chatbot: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"Erreur lors de la génération de la réponse: {str(e)}"
        )

@router.get("/node-summary/{node_pubkey}",
    summary="Résumé rapide d'un nœud",
    description="Résumé contextuel d'un nœud pour le chatbot",
    response_model=Dict[str, Any]
)
async def get_node_summary(
    node_pubkey: str,
    api_key: str = Depends(verify_api_key)
):
    """
    **Résumé rapide d'un nœud pour le chatbot**
    
    Fournit un aperçu rapide des métriques clés d'un nœud
    pour alimenter les conversations du chatbot.
    """
    
    try:
        node_data = await chatbot_intelligence.analyze_node_context(node_pubkey)
        
        # Simplifier pour un résumé rapide
        summary = {
            "alias": node_data.get("alias"),
            "pubkey_short": node_pubkey[:16] + "...",
            "performance_score": 0,  # À calculer
            "key_metrics": {},
            "status": "analyzed" if not node_data.get("error") else "error"
        }
        
        if node_data.get("centrality"):
            cent = node_data["centrality"]
            summary["key_metrics"]["centrality"] = {
                "degree": round(cent.get("degree_centrality", 0), 3),
                "position": "hub" if cent.get("degree_centrality", 0) > 0.1 else "standard"
            }
            summary["performance_score"] += 30
            
        if node_data.get("financial"):
            fin = node_data["financial"]
            summary["key_metrics"]["financial"] = {
                "roi_annual": round(fin.get("annual_roi_percent", 0), 2),
                "profitability": "good" if fin.get("annual_roi_percent", 0) > 5 else "moderate"
            }
            summary["performance_score"] += 40
        
        return summary
        
    except Exception as e:
        logger.error(f"Erreur résumé nœud {node_pubkey}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/conversation/context",
    summary="Contexte de conversation",
    description="Maintient le contexte d'une conversation chatbot"
)
async def update_conversation_context(
    conversation_id: str,
    context: Dict[str, Any] = Body(...),
    api_key: str = Depends(verify_api_key)
):
    """
    **Gestion du contexte conversationnel**
    
    Permet de maintenir le contexte d'une conversation
    pour des réponses plus cohérentes.
    """
    
    # Pour l'instant, simple stockage en mémoire
    # En production, utiliser Redis ou une base de données
    
    return {
        "conversation_id": conversation_id,
        "context_updated": True,
        "timestamp": datetime.utcnow().isoformat()
    }
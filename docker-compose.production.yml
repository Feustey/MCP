# Docker Compose Unifié MCP Production
# Version consolidée sans Grafana/Prometheus
# Dernière mise à jour: 27 août 2025

version: '3.8'

services:
  # ============================================
  # REVERSE PROXY PRINCIPAL
  # ============================================
  nginx:
    image: nginx:alpine
    container_name: mcp-nginx-prod
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx/ssl-production.conf:/etc/nginx/conf.d/default.conf:ro
      - ./config/nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - mcp-api
      # - t4g-api  # Commenté tant que t4g n'est pas disponible
    networks:
      - mcp-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # ============================================
  # MCP API PRINCIPAL avec RAG
  # ============================================
  mcp-api:
    image: feustey/mcp-dazno:fixed-amd64
    container_name: mcp-api-prod
    restart: always
    working_dir: /app
    entrypoint: []
    command: ["bash", "/app/scripts/simple_entrypoint.sh"]
    expose:
      - "8000"
    environment:
      # Configuration serveur
      - ENVIRONMENT=production
      - DEBUG=false
      - HOST=0.0.0.0
      - PORT=8000
      - WORKERS=4
      - RELOAD=false
      
      # Base de données - Utiliser les variables d'environnement
      - MONGO_URL=${MONGO_URL}
      - REDIS_URL=${REDIS_URL}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_USERNAME=${REDIS_USERNAME}
      
      # Sécurité et JWT - OBLIGATOIRE sans fallback
      - JWT_SECRET=${JWT_SECRET}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - SECRET_KEY=${SECRET_KEY}
      - SECURITY_SECRET_KEY=${SECURITY_SECRET_KEY}
      - CORS_ORIGINS=https://app.dazno.de,https://api.dazno.de,https://token-for-good.com,http://localhost:3000
      
      # Services Lightning
      - LIGHTNING_ADDRESS=${LIGHTNING_ADDRESS}
      - LNBITS_URL=${LNBITS_URL:-https://lnbits.dazno.de}
      - LNBITS_ADMIN_KEY=${LNBITS_ADMIN_KEY}
      - LNBITS_INKEY=${LNBITS_INKEY}
      
      # Intelligence Artificielle
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - AI_OPENAI_API_KEY=${AI_OPENAI_API_KEY}
      
      # Configuration RAG
      - RAG_ENABLED=true
      - RAG_DATA_PATH=/app/rag
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_COLLECTION=mcp_knowledge
      # Ollama (LLM local) + Llama3 70B
      - OLLAMA_URL=http://ollama:11434
      - GEN_MODEL=llama3:70b-instruct-2025-07-01
      - EMBED_MODEL=nomic-embed-text
      
      # APIs externes
      - SPARKSEER_API_KEY=${SPARKSEER_API_KEY}
      - SPARKSEER_BASE_URL=https://api.sparkseer.space/v1/
      
      # Notifications
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
      
      # Performance et Rate Limiting
      - RATE_LIMIT_ENABLED=true
      - MAX_REQUESTS_PER_HOUR=1000
      - BATCH_SIZE=10
      - MAX_CONCURRENT_REQUESTS=10
      - REQUEST_TIMEOUT=60
      
      # Logging
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
      - LOG_FILE=/app/logs/mcp.log
      
      # Python
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONPATH=/app:/app/src
    volumes:
      - ./mcp-data/logs:/app/logs
      - ./mcp-data/data:/app/data
      - ./mcp-data/rag:/app/rag
      - ./mcp-data/backups:/app/backups
      - ./mcp-data/reports:/app/reports
      - ./config:/app/config:ro
      - ./config.py:/app/config.py:ro
      - ./src:/app/src:ro
      - ./app:/app/app:ro
      - ./scripts/simple_entrypoint.sh:/app/scripts/simple_entrypoint.sh:ro
    networks:
      - mcp-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 60s
    depends_on:
      - mongodb
      - redis
      - qdrant
      - ollama

  # ============================================
  # TOKEN-FOR-GOOD API (Service secondaire optionnel)
  # ============================================
  # NOTE: Commenté car l'image n'existe pas encore
  # t4g-api:
  #   image: feustey/t4g:latest  # ou node:18-alpine avec build
  #   container_name: t4g-api-prod
  #   restart: always
  #   expose:
  #     - "8001"
  #   environment:
  #     - NODE_ENV=production
  #     - PORT=8001
  #     - MONGO_URL=mongodb+srv://feustey:sIiEp8oiB2hjYBbi@dazia.pin4fwl.mongodb.net/t4g?retryWrites=true&w=majority&appName=Dazia
  #     - REDIS_URL=redis://default:EqbM5xJAkh9gvdOyVoYiWR9EoHRBXcjY@redis-16818.crce202.eu-west-3-1.ec2.redns.redis-cloud.com:16818/1
  #     - JWT_SECRET=${T4G_JWT_SECRET}
  #     - API_KEY=${T4G_API_KEY}
  #     - CORS_ORIGINS=https://app.dazno.de,https://token-for-good.com,http://localhost:3000
  #     - SUPABASE_URL=${SUPABASE_URL}
  #     - SUPABASE_ROLE=${SUPABASE_ROLE}
  #     - LOG_LEVEL=info
  #   volumes:
  #     - ./t4g-data/logs:/app/logs
  #     - ./t4g-data/uploads:/app/uploads
  #     - ./t4g-data/data:/app/data
  #   healthcheck:
  #     test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 3
  #     start_period: 30s
  #   networks:
  #     - mcp-network

  # ============================================
  # QDRANT VECTOR DATABASE (RAG)
  # ============================================
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: mcp-qdrant-prod
    restart: always
    expose:
      - "6333"
      - "6334"
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__LOG_LEVEL=INFO
      - QDRANT__STORAGE__STORAGE_PATH=/qdrant/storage
      - QDRANT__SERVICE__MAX_REQUEST_SIZE_MB=100
      - QDRANT__SERVICE__MAX_WORKERS=4
    volumes:
      - qdrant_data:/qdrant/storage
      - ./config/qdrant:/qdrant/config:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - mcp-network

  # ============================================
  # OLLAMA (LLM local pour Llama 3 70B + embeddings)
  # ============================================
  ollama:
    image: ollama/ollama:latest
    container_name: mcp-ollama
    restart: always
    expose:
      - "11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_KEEP_ALIVE=30m
      - OLLAMA_NUM_PARALLEL=1  # 1 seule requête à la fois pour 70B
      # CPU/Thread config (ajuster selon votre hardware)
      # - OLLAMA_NUM_THREADS=16  # Utiliser tous les cœurs physiques
      # - OMP_NUM_THREADS=16
      # GPU NVIDIA (décommenter si disponible)
      # - NVIDIA_VISIBLE_DEVICES=all
      # - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # - CUDA_VISIBLE_DEVICES=0
    volumes:
      - ollama_data:/root/.ollama
      - ./scripts/ollama_init.sh:/scripts/ollama_init.sh:ro
    # Décommenter pour GPU NVIDIA
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    networks:
      - mcp-network
    # Note: Pour initialiser les modèles au premier démarrage, exécuter:
    # docker exec mcp-ollama ollama pull llama3:70b-instruct-2025-07-01
    # docker exec mcp-ollama ollama pull llama3:8b-instruct
    # docker exec mcp-ollama ollama pull nomic-embed-text


  # ============================================
  # MONGODB LOCAL (Base de données)
  # ============================================
  mongodb:
    image: mongo:7.0
    container_name: mcp-mongodb-prod
    restart: always
    expose:
      - "27017"
    environment:
      - MONGO_INITDB_ROOT_USERNAME=mcp_admin
      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_ROOT_PASSWORD:-mcp_secure_password_2025}
      - MONGO_INITDB_DATABASE=mcp_prod
    volumes:
      - mongodb_data:/data/db
      - mongodb_config:/data/configdb
      - ./backups/mongodb:/backup
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - mcp-network

  # ============================================
  # REDIS LOCAL (Cache)
  # ============================================
  redis:
    image: redis:7-alpine
    container_name: mcp-redis-prod
    restart: always
    expose:
      - "6379"
    command: redis-server --requirepass ${REDIS_PASSWORD:-mcp_redis_password_2025}
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD:-mcp_redis_password_2025}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - mcp-network

  # ============================================
  # BACKUP SERVICE (Optionnel - Cron Job)
  # ============================================
  backup:
    image: alpine:3.18
    container_name: mcp-backup-prod
    restart: "no"
    volumes:
      - ./mcp-data:/backup/mcp-data:ro
      - ./t4g-data:/backup/t4g-data:ro
      - mongodb_data:/backup/mongodb:ro
      - redis_data:/backup/redis:ro
      - qdrant_data:/backup/qdrant:ro
      - ./backups:/backup/output
      - ./scripts:/scripts:ro
    networks:
      - mcp-network
    command: >
      sh -c "
        apk add --no-cache curl tar gzip rsync &&
        echo 'Backup service ready' &&
        if [ -f /scripts/backup.sh ]; then
          sh /scripts/backup.sh
        else
          echo 'No backup script found, service idle'
        fi &&
        tail -f /dev/null
      "

volumes:
  qdrant_data:
    driver: local
    name: mcp_qdrant_data
  ollama_data:
    driver: local
    name: mcp_ollama_data
  mongodb_data:
    driver: local
    name: mcp_mongodb_data
  mongodb_config:
    driver: local
    name: mcp_mongodb_config
  redis_data:
    driver: local
    name: mcp_redis_data

networks:
  mcp-network:
    driver: bridge
    name: mcp_production_network
    ipam:
      config:
        - subnet: 172.28.0.0/16
    driver_opts:
      com.docker.network.bridge.name: mcp-prod-bridge

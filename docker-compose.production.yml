# Docker Compose pour déploiement MCP Production sur Hostinger
# Version simplifiée sans monitoring
# Dernière mise à jour: 22 août 2025

services:
  # Service principal MCP
  mcp-api:
    build:
      context: .
      dockerfile: Dockerfile
    image: feustey/dazno:latest
    container_name: mcp-api-production
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # Configuration de base
      - ENVIRONMENT=production
      - DEBUG=false
      - DRY_RUN=false
      - LOG_LEVEL=info
      
      # Configuration serveur
      - HOST=0.0.0.0
      - PORT=8000
      - RELOAD=false
      - WORKERS=4
      
      # Base de données MongoDB (Hostinger)
      - MONGO_URL=mongodb://root:8qsY4vHBSoltyy23ItSbZOiXeJpxtyCLzZBWjfylAFyh8hQRl61PVbwhUZpaMGrJ@b44g08c0kkggckwswswck8ks:27017/?directConnection=true
      - MONGO_NAME=mcp
      
      # Redis (Hostinger)
      - REDIS_HOST=d4s8888skckos8c80w4swgcw
      - REDIS_PORT=6379
      - REDIS_USERNAME=default
      - REDIS_PASSWORD=YnsPl4fmrjv7i3ZO546O4zsXRsRO3O3vNMbCZAJ5sNlu7oMmj20WYrtOn33kjmo1
      - REDIS_SSL=true
      - REDIS_MAX_CONNECTIONS=20
      
      # Configuration IA
      - AI_OPENAI_API_KEY=${AI_OPENAI_API_KEY:-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}
      - AI_OPENAI_MODEL=gpt-3.5-turbo
      - AI_OPENAI_EMBEDDING_MODEL=text-embedding-3-small
      
      # Configuration Lightning
      - LIGHTNING_LND_HOST=localhost:10009
      - LIGHTNING_LND_REST_URL=https://127.0.0.1:8080
      - LIGHTNING_USE_INTERNAL_LNBITS=false
      - LIGHTNING_LNBITS_URL=http://127.0.0.1:8000/lnbits
      - LNBITS_INKEY=${LNBITS_INKEY:-3fbbe7e0c2a24b43aa2c6ad6627f44eb}
      
      # Configuration sécurité
      - SECURITY_SECRET_KEY=${SECURITY_SECRET_KEY:-eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0ZW5hbnRfaWQiOiJtb24tdGVuYW50LWlkIiwiZXhwIjoxNzQ3MzM5NzAzfQ.-5mgm01tuSlQQXtZIa35c9MUBdpB1WFyf6kPzk53TGY}
      - SECURITY_CORS_ORIGINS=["*"]
      - SECURITY_ALLOWED_HOSTS=["*"]
      
      # Configuration performance
      - PERF_RESPONSE_CACHE_TTL=3600
      - PERF_EMBEDDING_CACHE_TTL=86400
      - PERF_MAX_WORKERS=4
      
      # Configuration logging
      - LOG_LEVEL=info
      - LOG_FORMAT=json
      - LOG_ENABLE_STRUCTLOG=true
      - LOG_ENABLE_FILE_LOGGING=true
      - LOG_LOG_FILE_PATH=logs/mcp.log
      
      # Configuration heuristiques
      - HEURISTIC_CENTRALITY_WEIGHT=0.4
      - HEURISTIC_CAPACITY_WEIGHT=0.2
      - HEURISTIC_REPUTATION_WEIGHT=0.2
      - HEURISTIC_FEES_WEIGHT=0.1
      - HEURISTIC_UPTIME_WEIGHT=0.1
      - HEURISTIC_VECTOR_WEIGHT=0.7
      
      # Configuration Python
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONPATH=/app
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./rag:/app/rag
    networks:
      - mcp-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    security_opt:
      - no-new-privileges:true

  # Reverse proxy avec Nginx
  nginx:
    image: nginx:alpine
    container_name: mcp-nginx-production
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - mcp-api
    networks:
      - mcp-network
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Base vectorielle Qdrant pour RAG
  qdrant:
    image: qdrant/qdrant:latest
    container_name: mcp-qdrant-production
    restart: unless-stopped
    ports:
      - "127.0.0.1:6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage
      - ./config/qdrant/config.yaml:/qdrant/config/production.yaml:ro
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__CLUSTER__ENABLED=false
      - QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS=4
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:6333/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - mcp-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    security_opt:
      - no-new-privileges:true

volumes:
  qdrant_data:
    driver: local

networks:
  mcp-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
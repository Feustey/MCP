# Scripts Ollama pour MCP

> Scripts de d√©ploiement, validation et maintenance pour l'int√©gration Ollama/Llama 3

## üìã Liste des scripts

### 1. `ollama_init.sh`
**Initialisation des mod√®les Ollama**

```bash
# Usage (depuis le conteneur Ollama)
docker exec mcp-ollama /scripts/ollama_init.sh
```

**Fonctions:**
- Pull des 3 mod√®les requis (70B, 8B, embeddings)
- V√©rification des mod√®les existants (skip si d√©j√† pr√©sent)
- Warmup du mod√®le principal
- Logs d√©taill√©s avec indicateurs de progression

**Mod√®les install√©s:**
- `llama3:70b-instruct-2025-07-01` (~40 GB)
- `llama3:8b-instruct` (~4.7 GB)
- `nomic-embed-text` (~274 MB)

**Dur√©e:** 1-3h selon la connexion (premi√®re fois)

---

### 2. `validate_ollama_integration.sh`
**Validation compl√®te de l'int√©gration**

```bash
# Usage
./scripts/validate_ollama_integration.sh
```

**V√©rifications (8 √©tapes):**
1. ‚úÖ Pr√©sence des fichiers source
2. ‚úÖ Configuration .env
3. ‚úÖ Docker Compose
4. ‚úÖ Syntaxe Python
5. ‚úÖ Tests unitaires (29 tests)
6. ‚úÖ Service Ollama (si running)
7. ‚úÖ Service MCP API (si running)
8. ‚úÖ Documentation

**Sortie:** 
- ‚úÖ Validation r√©ussie (exit 0)
- ‚ùå Erreurs d√©tect√©es (exit 1)

**Logs:** `/tmp/test_ollama_*.log`

---

### 3. `deploy_ollama.sh`
**D√©ploiement automatis√© complet**

```bash
# Usage
./scripts/deploy_ollama.sh [dev|prod]

# Exemples
./scripts/deploy_ollama.sh dev   # Installe uniquement 8B (rapide)
./scripts/deploy_ollama.sh prod  # Installe 70B + 8B + embeddings (complet)
```

**√âtapes (7 au total):**
1. Arr√™t des services existants
2. Cr√©ation/v√©rification des volumes
3. D√©marrage Ollama
4. Attente healthcheck (max 60s)
5. Initialisation des mod√®les
6. Affichage des mod√®les install√©s
7. D√©marrage API MCP + tests de validation

**Mode dev:**
- Installe uniquement Llama 3 8B + embeddings
- Rapide (~10 min)
- Id√©al pour d√©veloppement/tests

**Mode prod:**
- Installe Llama 3 70B + 8B + embeddings
- Long (~1-3h premi√®re fois)
- Pr√™t pour production

**Tests automatiques:**
- Import client Ollama
- Import adaptateur RAG
- Healthcheck Ollama depuis API

---

## üöÄ Workflow recommand√©

### Premi√®re installation

```bash
# 1. Valider l'int√©gration (code, config, tests)
./scripts/validate_ollama_integration.sh

# 2. D√©ployer en mode dev (rapide)
./scripts/deploy_ollama.sh dev

# 3. Tester manuellement
docker exec mcp-api python3 -c "
from src.clients.ollama_client import ollama_client
import asyncio
emb = asyncio.run(ollama_client.embed('test'))
print(f'‚úÖ OK: dimension={len(emb)}')
"

# 4. Si OK, upgrader vers prod (optionnel)
docker exec mcp-ollama ollama pull llama3:70b-instruct-2025-07-01
```

### Mise √† jour

```bash
# 1. Valider les changements
./scripts/validate_ollama_integration.sh

# 2. Re-d√©ployer
./scripts/deploy_ollama.sh prod

# 3. V√©rifier les logs
docker logs -f mcp-api
```

### Troubleshooting

```bash
# Validation compl√®te
./scripts/validate_ollama_integration.sh

# V√©rifier les mod√®les
docker exec mcp-ollama ollama list

# R√©initialiser les mod√®les
docker exec mcp-ollama /scripts/ollama_init.sh

# Red√©marrer les services
docker-compose restart ollama mcp-api
```

---

## üìä Codes de sortie

| Script | Exit 0 | Exit 1 |
|--------|--------|--------|
| `validate_ollama_integration.sh` | Tous les tests OK | Erreur(s) d√©tect√©e(s) |
| `deploy_ollama.sh` | D√©ploiement r√©ussi | Erreur de d√©ploiement |
| `ollama_init.sh` | Mod√®les install√©s | Erreur de pull |

---

## üîß Variables d'environnement

Ces scripts utilisent `.env` pour la configuration. Cr√©er depuis `env.ollama.example`:

```bash
cp env.ollama.example .env
# √âditer .env avec vos valeurs
```

**Variables cl√©s:**
- `LLM_PROVIDER=ollama`
- `OLLAMA_URL=http://ollama:11434`
- `GEN_MODEL=llama3:70b-instruct-2025-07-01`
- `GEN_MODEL_FALLBACK=llama3:8b-instruct`
- `EMBED_MODEL=nomic-embed-text`

---

## üìö Ressources

- **[QUICKSTART_OLLAMA.md](../QUICKSTART_OLLAMA.md)** - D√©marrage rapide
- **[OLLAMA_INTEGRATION_GUIDE.md](../docs/OLLAMA_INTEGRATION_GUIDE.md)** - Guide complet
- **[TODO_NEXT_OLLAMA.md](../TODO_NEXT_OLLAMA.md)** - Prochaines √©tapes

---

## ‚ö†Ô∏è Notes importantes

### Ressources requises

**Pour mode dev (8B):**
- Espace disque: ~10 GB
- RAM: 8-16 GB
- GPU: Optionnel (RTX 3060+)

**Pour mode prod (70B):**
- Espace disque: ~50 GB
- RAM: 64+ GB ou GPU avec 48+ GB VRAM
- GPU: Fortement recommand√© (A100, H100, 2√ó RTX 4090)

### Temps d'installation

| Mod√®le | Taille | Temps (100 Mbps) | Temps (1 Gbps) |
|--------|--------|------------------|----------------|
| 70B | ~40 GB | ~1h | ~10 min |
| 8B | ~4.7 GB | ~6 min | ~1 min |
| Embeddings | ~274 MB | ~20s | ~2s |

### Premi√®re utilisation

Le **premier appel** apr√®s installation sera lent (chargement en m√©moire):
- 70B: 30-60s
- 8B: 5-10s

Ensuite, rapide gr√¢ce √† `OLLAMA_KEEP_ALIVE=30m`.

---

**Derni√®re mise √† jour:** 16 octobre 2025


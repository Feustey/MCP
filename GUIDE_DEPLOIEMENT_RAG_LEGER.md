# ğŸš€ Guide de DÃ©ploiement RAG - ModÃ¨les LÃ©gers (llama3:8b-instruct)

> **Date:** 20 octobre 2025  
> **Version:** Production v1.0  
> **ModÃ¨le principal:** llama3:8b-instruct (~4.7 GB)  
> **ModÃ¨le fallback:** phi3:medium (~4.0 GB)  

---

## ğŸ“‹ Vue d'ensemble

Ce guide dÃ©crit le dÃ©ploiement complet du systÃ¨me RAG MCP avec des modÃ¨les Ollama lÃ©gers, optimisÃ©s pour la production avec des ressources limitÃ©es.

### Changements par rapport Ã  la version 70B

| Aspect | 70B (Ancien) | 8B (Nouveau) |
|--------|--------------|--------------|
| **ModÃ¨le principal** | llama3:70b-instruct | llama3:8b-instruct |
| **ModÃ¨le fallback** | qwen2.5:14b-instruct | phi3:medium |
| **RAM requise** | ~45 GB | ~6 GB |
| **Temps de rÃ©ponse** | 5-15s | 2-5s |
| **Throughput** | ~3 tokens/s | ~12 tokens/s |
| **PrÃ©cision** | ~95% | ~85-90% |
| **CoÃ»t infra/mois** | $200-400 | $50-100 |

---

## âœ… PrÃ©-requis

### SystÃ¨me

- **RAM:** Minimum 8 GB (16 GB recommandÃ©)
- **Stockage:** 15 GB libres minimum
- **CPU:** 4 cores minimum
- **OS:** Linux (Ubuntu 20.04+) ou macOS

### Logiciels

- Docker 24.0+
- Docker Compose 2.0+
- Git
- Curl

### Ports requis

- `8000`: API MCP
- `11434`: Ollama
- `27017`: MongoDB (interne Docker)
- `6379`: Redis (interne Docker)
- `3000`: Grafana (optionnel)
- `9090`: Prometheus (optionnel)

---

## ğŸ“¥ Ã‰tape 1 : RÃ©cupÃ©ration du Code

```bash
# Si pas encore clonÃ©
cd /Users/stephanecourant/Documents/DAZ/MCP/MCP

# VÃ©rifier que les fichiers sont Ã  jour
git status
```

---

## âš™ï¸ Ã‰tape 2 : Configuration

### 2.1 CrÃ©er le fichier .env

```bash
# Copier le template
cp env.hostinger.example .env

# Ã‰diter avec vos valeurs
nano .env
```

### 2.2 Valeurs critiques Ã  configurer

```bash
# SECURITY - GÃ‰NÃ‰RER AVEC:
# python3 -c "import secrets; print(secrets.token_urlsafe(32))"
# python3 -c "import base64, os; print(base64.b64encode(os.urandom(32)).decode())"
SECRET_KEY=CHANGEZ_CETTE_CLE_SECRETE_32_CARACTERES_MINIMUM
ENCRYPTION_KEY=CHANGEZ_CETTE_CLE_CHIFFREMENT_BASE64

# MONGODB (Docker Internal)
MONGODB_PASSWORD=CHANGEZ_CE_MOT_DE_PASSE_MONGODB_123!

# REDIS (Docker Internal)
REDIS_PASSWORD=CHANGEZ_CE_MOT_DE_PASSE_REDIS_123!

# LNBITS
LNBITS_URL=https://your-lnbits-instance.com
LNBITS_ADMIN_KEY=your_lnbits_admin_key_here
LNBITS_INVOICE_KEY=your_lnbits_invoice_key_here

# RAG / OLLAMA - VÃ‰RIFIER CES VALEURS
GEN_MODEL=llama3:8b-instruct
GEN_MODEL_FALLBACK=phi3:medium
EMBED_MODEL=nomic-embed-text
```

### 2.3 VÃ©rifier la configuration

```bash
# VÃ©rifier que GEN_MODEL est bien configurÃ©
grep "GEN_MODEL" .env

# Devrait afficher:
# GEN_MODEL=llama3:8b-instruct
# GEN_MODEL_FALLBACK=phi3:medium
```

---

## ğŸš€ Ã‰tape 3 : DÃ©ploiement Automatique

### 3.1 Lancer le dÃ©ploiement complet

```bash
# Rendre le script exÃ©cutable (si pas dÃ©jÃ  fait)
chmod +x deploy_rag_production.sh

# Lancer le dÃ©ploiement
./deploy_rag_production.sh
```

Le script va automatiquement :
1. âœ… VÃ©rifier la prÃ©sence du fichier `.env`
2. âœ… Builder et dÃ©marrer les containers Docker
3. âœ… VÃ©rifier la santÃ© des services (MongoDB, Redis, Ollama, API)
4. âœ… TÃ©lÃ©charger les modÃ¨les Ollama (llama3:8b-instruct, phi3:medium, nomic-embed-text)
5. âœ… Tester le workflow RAG

**DurÃ©e estimÃ©e:** 15-30 minutes (selon la connexion internet)

---

## ğŸ”§ Ã‰tape 4 : DÃ©ploiement Manuel (Alternative)

Si vous prÃ©fÃ©rez un contrÃ´le manuel :

### 4.1 DÃ©marrer les services Docker

```bash
docker-compose -f docker-compose.hostinger.yml up -d --build
```

### 4.2 Attendre le dÃ©marrage (30-60s)

```bash
# VÃ©rifier les logs
docker-compose -f docker-compose.hostinger.yml logs -f
```

### 4.3 RÃ©cupÃ©rer les modÃ¨les Ollama

```bash
# Rendre le script exÃ©cutable
chmod +x scripts/pull_lightweight_models.sh

# Lancer le tÃ©lÃ©chargement
./scripts/pull_lightweight_models.sh
```

### 4.4 VÃ©rifier les modÃ¨les

```bash
docker exec mcp-ollama ollama list

# Devrait afficher:
# NAME                    ID              SIZE
# llama3:8b-instruct      abc123...       4.7 GB
# phi3:medium             def456...       4.0 GB
# nomic-embed-text        ghi789...       274 MB
```

---

## âœ… Ã‰tape 5 : Validation

### 5.1 VÃ©rifier les services

```bash
# Tous les containers doivent Ãªtre UP
docker-compose -f docker-compose.hostinger.yml ps

# VÃ©rifier l'API
curl http://localhost:8000/health

# Devrait retourner: {"status":"healthy"}
```

### 5.2 Tester le RAG

```bash
# Test simple via API
curl -X POST http://localhost:8000/api/v1/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Quelles sont les meilleures pratiques pour optimiser les frais Lightning?",
    "node_pubkey": "feustey"
  }'
```

### 5.3 Lancer le workflow RAG complet

```bash
./run_rag_workflow_prod.sh
```

### 5.4 VÃ©rifier les logs

```bash
# Logs API
docker-compose -f docker-compose.hostinger.yml logs -f mcp-api

# Logs Ollama
docker-compose -f docker-compose.hostinger.yml logs -f ollama

# Logs tous services
docker-compose -f docker-compose.hostinger.yml logs --tail=100
```

---

## ğŸ“Š Ã‰tape 6 : Monitoring

### 6.1 AccÃ¨s aux interfaces

- **API MCP:** http://localhost:8000
- **Documentation API:** http://localhost:8000/docs
- **Grafana:** http://localhost:3000 (admin/admin)
- **Prometheus:** http://localhost:9090

### 6.2 MÃ©triques Ã  surveiller

```bash
# Utilisation RAM du container Ollama
docker stats mcp-ollama

# VÃ©rifier les performances
docker exec mcp-ollama curl http://localhost:11434/api/tags
```

---

## ğŸ” DÃ©pannage

### ProblÃ¨me 1 : ModÃ¨le ne se tÃ©lÃ©charge pas

```bash
# Entrer dans le container
docker exec -it mcp-ollama bash

# Pull manuel
ollama pull llama3:8b-instruct
ollama pull phi3:medium
ollama pull nomic-embed-text

# Sortir
exit
```

### ProblÃ¨me 2 : API ne dÃ©marre pas

```bash
# VÃ©rifier les logs
docker-compose -f docker-compose.hostinger.yml logs mcp-api

# RedÃ©marrer le service
docker-compose -f docker-compose.hostinger.yml restart mcp-api
```

### ProblÃ¨me 3 : MongoDB connection failed

```bash
# VÃ©rifier MongoDB
docker-compose -f docker-compose.hostinger.yml exec mongodb mongosh --eval "db.runCommand('ping')"

# VÃ©rifier le mot de passe dans .env
grep MONGODB_PASSWORD .env
```

### ProblÃ¨me 4 : Out of Memory

```bash
# RÃ©duire le contexte dans config/rag_config.py
# GEN_NUM_CTX: int = 4096  # au lieu de 8192

# RÃ©duire la concurrence
# OLLAMA_NUM_PARALLEL: int = 1  # au lieu de 3
```

### ProblÃ¨me 5 : RÃ©ponses de mauvaise qualitÃ©

```bash
# 1. Essayer le fallback
# Dans .env, inverser:
# GEN_MODEL=phi3:medium
# GEN_MODEL_FALLBACK=llama3:8b-instruct

# 2. Ou passer Ã  un modÃ¨le plus gros:
# GEN_MODEL=qwen2.5:14b-instruct

# 3. Ajuster la tempÃ©rature dans config/rag_config.py
# GEN_TEMPERATURE: float = 0.2  # Plus conservateur
```

---

## ğŸ“ˆ Optimisations Post-DÃ©ploiement

### Optimisation 1 : Ajuster les paramÃ¨tres RAG

Ã‰diter `config/rag_config.py` :

```python
# Pour des rÃ©ponses plus rapides mais moins prÃ©cises
RAG_TOPK: int = 3  # au lieu de 5
RAG_RERANK_TOP: int = 1  # au lieu de 2

# Pour des rÃ©ponses plus prÃ©cises mais plus lentes
RAG_TOPK: int = 8
RAG_RERANK_TOP: int = 3
```

### Optimisation 2 : Caching agressif

```python
# Dans config/rag_config.py
CACHE_TTL_RETRIEVAL: int = 172800  # 48h au lieu de 24h
CACHE_TTL_ANSWER: int = 43200  # 12h au lieu de 6h
```

### Optimisation 3 : Warmup automatique

Ajouter au cron :

```bash
# Warmup toutes les heures pour maintenir le modÃ¨le en mÃ©moire
0 * * * * docker exec mcp-ollama ollama run llama3:8b-instruct "ping" > /dev/null 2>&1
```

---

## ğŸ”„ Workflow RAG AutomatisÃ©

### Configuration Cron pour exÃ©cution quotidienne

```bash
# Ã‰diter crontab
crontab -e

# Ajouter (exÃ©cution tous les jours Ã  3h du matin)
0 3 * * * cd /Users/stephanecourant/Documents/DAZ/MCP/MCP && ./run_rag_workflow_prod.sh >> logs/cron_rag.log 2>&1
```

### ExÃ©cution manuelle

```bash
# Workflow complet
./run_rag_workflow_prod.sh

# Workflow simplifiÃ©
./run_rag_workflow.sh
```

---

## ğŸ›‘ ArrÃªt et Maintenance

### ArrÃªt propre

```bash
# ArrÃªter tous les services
docker-compose -f docker-compose.hostinger.yml down

# ArrÃªter ET supprimer les volumes (âš ï¸ perte de donnÃ©es)
docker-compose -f docker-compose.hostinger.yml down -v
```

### RedÃ©marrage

```bash
# RedÃ©marrer tous les services
docker-compose -f docker-compose.hostinger.yml restart

# RedÃ©marrer un service spÃ©cifique
docker-compose -f docker-compose.hostinger.yml restart mcp-api
```

### Mise Ã  jour

```bash
# Pull la derniÃ¨re version
git pull origin main

# Rebuild et redÃ©marrer
docker-compose -f docker-compose.hostinger.yml up -d --build
```

### Sauvegarde

```bash
# Sauvegarder MongoDB
docker-compose -f docker-compose.hostinger.yml exec mongodb mongodump --out /data/backup

# Sauvegarder les modÃ¨les Ollama
docker exec mcp-ollama tar -czf /tmp/ollama_models.tar.gz /root/.ollama
docker cp mcp-ollama:/tmp/ollama_models.tar.gz ./backup/
```

---

## ğŸ“ Fichiers ModifiÃ©s

### Configuration

- âœ… `config/rag_config.py` - ParamÃ¨tres RAG optimisÃ©s pour 8B
- âœ… `env.hostinger.example` - Template avec modÃ¨les lÃ©gers
- âœ… `env.production.example` - Template production avec modÃ¨les lÃ©gers
- âœ… `docker-compose.hostinger.yml` - Configuration Docker avec modÃ¨les lÃ©gers
- âœ… `docker-compose.hostinger-production.yml` - Configuration production avec modÃ¨les lÃ©gers

### Scripts

- âœ… `scripts/pull_lightweight_models.sh` - TÃ©lÃ©chargement des modÃ¨les lÃ©gers
- âœ… `deploy_rag_production.sh` - DÃ©ploiement automatique complet

---

## ğŸ¯ MÃ©triques de SuccÃ¨s

### Performance attendue

```yaml
RÃ©ponse API:
  - P50: < 3s
  - P95: < 5s
  - P99: < 8s

Ressources:
  - RAM Ollama: ~6 GB
  - RAM API: ~512 MB
  - RAM MongoDB: ~256 MB
  - RAM Redis: ~128 MB
  - CPU moyen: < 30%

QualitÃ©:
  - PrÃ©cision rÃ©ponses: 85-90%
  - Taux d'erreur: < 5%
  - Cache hit rate: > 70%
```

### Tests de validation

```bash
# 1. Test de latence
time curl -X POST http://localhost:8000/api/v1/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Test", "node_pubkey": "feustey"}'

# 2. Test de charge (optionnel, nÃ©cessite apache-bench)
ab -n 100 -c 5 http://localhost:8000/health

# 3. Test workflow complet
time ./run_rag_workflow_prod.sh
```

---

## ğŸ“ Support

### En cas de problÃ¨me

1. **Consulter les logs:**
   ```bash
   docker-compose -f docker-compose.hostinger.yml logs --tail=100
   ```

2. **VÃ©rifier la configuration:**
   ```bash
   cat .env | grep -E "(GEN_MODEL|OLLAMA|MONGODB|REDIS)"
   ```

3. **Restart complet:**
   ```bash
   docker-compose -f docker-compose.hostinger.yml down
   docker-compose -f docker-compose.hostinger.yml up -d
   ```

### Ressources

- [Documentation Ollama](https://ollama.com/docs)
- [Docker Compose Docs](https://docs.docker.com/compose/)
- [Roadmap MCP v1.0](_SPECS/Roadmap-Production-v1.0.md)
- [Backbone Technique](docs/backbone-technique-MVP.md)

---

## âœ… Checklist Finale

Avant de considÃ©rer le dÃ©ploiement terminÃ© :

```
â˜‘ .env configurÃ© avec valeurs rÃ©elles
â˜‘ Tous les containers UP et healthy
â˜‘ Les 3 modÃ¨les Ollama tÃ©lÃ©chargÃ©s
â˜‘ API rÃ©pond sur /health
â˜‘ Test RAG query rÃ©ussi
â˜‘ Workflow RAG exÃ©cutÃ© sans erreur
â˜‘ Monitoring accessible (Grafana, Prometheus)
â˜‘ Logs vÃ©rifiÃ©s, pas d'erreur critique
â˜‘ Backup configurÃ© (optionnel)
â˜‘ Cron configurÃ© pour workflow automatique (optionnel)
```

---

**ğŸ‰ DÃ©ploiement RAG avec modÃ¨les lÃ©gers terminÃ© !**

> Pour toute question, consulter la roadmap production complÃ¨te dans `_SPECS/Roadmap-Production-v1.0.md`


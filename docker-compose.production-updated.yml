# Docker Compose MCP Production Optimisé
# Version avec build local et dépendances complètes
# Dernière mise à jour: 2025-09-24

version: '3.8'

services:
  # ============================================
  # MCP API PRINCIPAL avec RAG et Chatbot
  # ============================================
  mcp-api:
    build:
      context: .
      dockerfile: Dockerfile.production
    image: mcp-api:production
    container_name: mcp-api-prod
    restart: always
    working_dir: /app
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "2"]
    ports:
      - "8000:8000"
    environment:
      # Configuration serveur
      - ENVIRONMENT=production
      - DEBUG=false
      - HOST=0.0.0.0
      - PORT=8000
      
      # Base de données
      - MONGO_URL=${MONGO_URL}
      - MONGO_NAME=${MONGO_NAME:-mcp}
      - REDIS_URL=${REDIS_URL}
      - REDIS_HOST=${REDIS_HOST}
      - REDIS_PORT=${REDIS_PORT}
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - REDIS_USERNAME=${REDIS_USERNAME}
      
      # Sécurité et JWT
      - JWT_SECRET=${JWT_SECRET}
      - JWT_SECRET_KEY=${JWT_SECRET_KEY}
      - SECRET_KEY=${SECRET_KEY}
      - SECURITY_SECRET_KEY=${SECURITY_SECRET_KEY}
      - CORS_ORIGINS=https://app.dazno.de,https://api.dazno.de,https://token-for-good.com,http://localhost:3000
      
      # Services Lightning
      - LIGHTNING_ADDRESS=${LIGHTNING_ADDRESS}
      - LNBITS_URL=${LNBITS_URL:-https://lnbits.dazno.de}
      - LNBITS_ADMIN_KEY=${LNBITS_ADMIN_KEY}
      - LNBITS_INKEY=${LNBITS_INKEY}
      
      # Intelligence Artificielle
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - AI_OPENAI_API_KEY=${AI_OPENAI_API_KEY}
      - AI_OPENAI_MODEL=${AI_OPENAI_MODEL:-gpt-4o-mini}
      - AI_OPENAI_EMBEDDING_MODEL=${AI_OPENAI_EMBEDDING_MODEL:-text-embedding-ada-002}
      - AI_MAX_OUTPUT_TOKENS=${AI_MAX_OUTPUT_TOKENS:-600}
      
      # Configuration RAG
      - RAG_ENABLED=true
      - RAG_DATA_PATH=/app/rag
      - QDRANT_URL=http://qdrant:6333
      - QDRANT_COLLECTION=mcp_knowledge
      - QDRANT_VECTOR_SIZE=1536
      - QDRANT_DISTANCE=Cosine
      - MODEL_NAME=${MODEL_NAME:-gpt-4o-mini}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-ada-002}
      
      # APIs externes
      - SPARKSEER_API_KEY=${SPARKSEER_API_KEY}
      - SPARKSEER_BASE_URL=https://api.sparkseer.space/v1/
      
      # Notifications
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
      
      # Performance
      - RATE_LIMIT_ENABLED=true
      - MAX_REQUESTS_PER_HOUR=1000
      - BATCH_SIZE=10
      - MAX_CONCURRENT_REQUESTS=10
      - REQUEST_TIMEOUT=60
      - PERF_ENABLE_METRICS=true
      - PERF_RESPONSE_CACHE_TTL=3600
      - PERF_EMBEDDING_CACHE_TTL=86400
      - PERF_MAX_WORKERS=4
      
      # Logging
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
      - LOG_FILE=/app/logs/mcp.log
      - LOG_ENABLE_STRUCTLOG=true
      - LOG_ENABLE_FILE_LOGGING=true
      - LOG_LOG_FILE_PATH=/app/logs/mcp.log
      - LOG_MAX_FILE_SIZE=10485760
      - LOG_BACKUP_COUNT=5
      
      # Heuristiques
      - HEURISTIC_CENTRALITY_WEIGHT=0.4
      - HEURISTIC_CAPACITY_WEIGHT=0.2
      - HEURISTIC_REPUTATION_WEIGHT=0.2
      - HEURISTIC_FEES_WEIGHT=0.1
      - HEURISTIC_UPTIME_WEIGHT=0.1
      - HEURISTIC_VECTOR_WEIGHT=0.7
      
      # Python
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
      - PYTHONPATH=/app:/app/src
    volumes:
      - ./mcp-data/logs:/app/logs
      - ./mcp-data/data:/app/data
      - ./mcp-data/rag:/app/rag
      - ./mcp-data/backups:/app/backups
      - ./mcp-data/reports:/app/reports
      - ./config:/app/config:ro
      - ./config.py:/app/config.py:ro
      - ./src:/app/src:ro
      - ./app:/app/app:ro
      - ./requirements-production.txt:/app/requirements.txt:ro
      - ./.env:/app/.env:ro
    networks:
      - mcp-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 90s
    depends_on:
      qdrant:
        condition: service_healthy

  # ============================================
  # QDRANT VECTOR DATABASE (RAG)
  # ============================================
  qdrant:
    image: qdrant/qdrant:v1.7.4
    container_name: mcp-qdrant-prod
    restart: always
    ports:
      - "6333:6333"
      - "6334:6334"
    environment:
      - QDRANT__SERVICE__HTTP_PORT=6333
      - QDRANT__SERVICE__GRPC_PORT=6334
      - QDRANT__LOG_LEVEL=INFO
      - QDRANT__STORAGE__STORAGE_PATH=/qdrant/storage
      - QDRANT__SERVICE__MAX_REQUEST_SIZE_MB=100
      - QDRANT__SERVICE__MAX_WORKERS=4
    volumes:
      - qdrant_data:/qdrant/storage
      - ./config/qdrant:/qdrant/config:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6333/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - mcp-network

  # ============================================
  # NGINX REVERSE PROXY (Optionnel)
  # ============================================
  nginx:
    image: nginx:alpine
    container_name: mcp-nginx-prod
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./config/nginx/production.conf:/etc/nginx/conf.d/default.conf:ro
      - ./config/nginx/ssl:/etc/nginx/ssl:ro
      - ./logs/nginx:/var/log/nginx
    depends_on:
      - mcp-api
    networks:
      - mcp-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  qdrant_data:
    driver: local
    name: mcp_qdrant_data

networks:
  mcp-network:
    driver: bridge
    name: mcp_production_network
    ipam:
      config:
        - subnet: 172.28.0.0/16
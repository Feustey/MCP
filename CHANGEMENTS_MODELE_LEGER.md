# üìù R√©sum√© des Changements - Passage au Mod√®le L√©ger

> **Date:** 20 octobre 2025  
> **Changement:** llama3:70b-instruct ‚Üí llama3:8b-instruct

---

## üéØ Objectif

R√©duire les ressources n√©cessaires pour le d√©ploiement du syst√®me RAG MCP en production, tout en maintenant une qualit√© acceptable pour les cas d'usage principaux.

---

## üìã Fichiers Modifi√©s

### 1. Configuration RAG - `config/rag_config.py`

#### Mod√®les

```python
# AVANT
GEN_MODEL: str = "llama3:70b-instruct-2024-07-xx"
GEN_MODEL_FALLBACK: str = "qwen2.5:14b-instruct"
LLM_MODEL: str = "llama3.1:8b-instruct"
OLLAMA_NUM_PARALLEL: int = 1

# APR√àS
GEN_MODEL: str = "llama3:8b-instruct"
GEN_MODEL_FALLBACK: str = "phi3:medium"
LLM_MODEL: str = "llama3:8b-instruct"
OLLAMA_NUM_PARALLEL: int = 3
```

#### Param√®tres de g√©n√©ration

```python
# AVANT
GEN_TEMPERATURE: float = 0.2
GEN_MAX_TOKENS: int = 1536
LLM_TIMEOUT: int = 90

# APR√àS (optimis√©s pour mod√®le 8B)
GEN_TEMPERATURE: float = 0.3
GEN_MAX_TOKENS: int = 1200
LLM_TIMEOUT: int = 120
```

#### Param√®tres de retrieval

```python
# AVANT
RAG_TOPK: int = 8
RAG_RERANK_TOP: int = 3
RAG_CONFIDENCE_THRESHOLD: float = 0.35

# APR√àS (optimis√©s pour mod√®le l√©ger)
RAG_TOPK: int = 5
RAG_RERANK_TOP: int = 2
RAG_CONFIDENCE_THRESHOLD: float = 0.40
```

---

### 2. Templates d'Environnement

#### `env.hostinger.example`

```bash
# AVANT
GEN_MODEL=llama3:70b-instruct-2024-07-xx
GEN_MODEL_FALLBACK=qwen2.5:14b-instruct

# APR√àS
GEN_MODEL=llama3:8b-instruct
GEN_MODEL_FALLBACK=phi3:medium
```

#### `env.production.example`

```bash
# AVANT
GEN_MODEL=llama3:70b-instruct-2024-07-xx
GEN_MODEL_FALLBACK=qwen2.5:14b-instruct

# APR√àS
GEN_MODEL=llama3:8b-instruct
GEN_MODEL_FALLBACK=phi3:medium
```

---

### 3. Docker Compose

#### `docker-compose.hostinger.yml`

```yaml
# AVANT
- GEN_MODEL=${GEN_MODEL:-llama3:70b-instruct-2024-07-xx}
- GEN_MODEL_FALLBACK=${GEN_MODEL_FALLBACK:-qwen2.5:14b-instruct}

# APR√àS
- GEN_MODEL=${GEN_MODEL:-llama3:8b-instruct}
- GEN_MODEL_FALLBACK=${GEN_MODEL_FALLBACK:-phi3:medium}
```

#### `docker-compose.hostinger-production.yml`

```yaml
# AVANT
- GEN_MODEL=${GEN_MODEL:-llama3:70b-instruct-2024-07-xx}
- GEN_MODEL_FALLBACK=${GEN_MODEL_FALLBACK:-qwen2.5:14b-instruct}

# APR√àS
- GEN_MODEL=${GEN_MODEL:-llama3:8b-instruct}
- GEN_MODEL_FALLBACK=${GEN_MODEL_FALLBACK:-phi3:medium}
```

---

## üÜï Nouveaux Fichiers Cr√©√©s

### 1. `scripts/pull_lightweight_models.sh`

Script automatis√© pour t√©l√©charger les mod√®les l√©gers :
- llama3:8b-instruct (~4.7 GB)
- phi3:medium (~4.0 GB)
- nomic-embed-text (~274 MB)

**Fonctionnalit√©s:**
- D√©tection automatique Docker vs local
- V√©rification des mod√®les existants
- Test de warmup
- Support mode interactif

### 2. `deploy_rag_production.sh`

Script de d√©ploiement complet en production :
- V√©rification de la configuration
- Build et d√©marrage Docker
- Health checks des services
- Pull des mod√®les Ollama
- Test du workflow RAG
- R√©sum√© final avec commandes utiles

### 3. `GUIDE_DEPLOIEMENT_RAG_LEGER.md`

Documentation compl√®te incluant :
- Pr√©-requis syst√®me
- Configuration pas-√†-pas
- D√©ploiement automatique et manuel
- Validation et tests
- Monitoring et m√©triques
- D√©pannage d√©taill√©
- Optimisations post-d√©ploiement
- Maintenance et backup

### 4. `CHANGEMENTS_MODELE_LEGER.md`

Ce document - R√©sum√© de tous les changements.

---

## üìä Comparaison des Mod√®les

| Aspect | llama3:70B | llama3:8B |
|--------|------------|-----------|
| **Taille t√©l√©chargement** | ~40 GB | ~4.7 GB |
| **RAM requise** | 40-50 GB | 6-8 GB |
| **Temps r√©ponse moyen** | 5-15s | 2-5s |
| **Throughput** | ~3 tokens/s | ~12 tokens/s |
| **Concurrence max** | 1-2 requ√™tes | 3-5 requ√™tes |
| **Pr√©cision g√©n√©rale** | ~95% | ~85-90% |
| **Co√ªt serveur/mois** | $200-400 | $50-100 |

---

## ‚úÖ Avantages du Mod√®le L√©ger

### Performance

- ‚ö° **4x plus rapide** pour g√©n√©rer les r√©ponses
- üîÑ **3x plus de concurrence** possible
- üíæ **8x moins de RAM** requise
- üì¶ **8x plus rapide** √† t√©l√©charger

### Co√ªt

- üí∞ **~70% de r√©duction** des co√ªts d'infrastructure
- üåç Peut tourner sur des serveurs standards
- ‚òÅÔ∏è Compatible avec des instances cloud √©conomiques

### D√©ploiement

- üöÄ D√©marrage plus rapide
- üîß Maintenance simplifi√©e
- üìà Scaling plus facile

---

## ‚ö†Ô∏è Limitations du Mod√®le L√©ger

### Qualit√©

- ‚ùå **Moins pr√©cis** pour les analyses complexes (-5 √† -10%)
- ‚ùå **Moins de nuances** dans les r√©ponses
- ‚ùå **Contexte limit√©** pour les raisonnements profonds

### Cas d'usage moins adapt√©s

- Analyses financi√®res complexes
- Raisonnement multi-√©tapes sophistiqu√©
- G√©n√©ration de code complexe
- Traduction de textes techniques longs

### Cas d'usage toujours adapt√©s ‚úÖ

- FAQ et r√©ponses directes
- R√©sum√©s de documents
- Recommandations basiques
- Classification de textes
- Extraction d'informations
- Chat conversationnel

---

## üéØ Recommandations d'Usage

### Utiliser le mod√®le 8B pour :

‚úÖ Recommandations de frais Lightning simples  
‚úÖ Analyses de m√©triques de n≈ìud  
‚úÖ R√©sum√©s de rapports  
‚úÖ R√©ponses aux questions fr√©quentes  
‚úÖ Classification de canaux  

### Envisager le mod√®le 14B (fallback) ou plus pour :

‚ö†Ô∏è Analyses de strat√©gies complexes  
‚ö†Ô∏è Optimisations multi-crit√®res  
‚ö†Ô∏è Pr√©dictions bas√©es sur historique long  
‚ö†Ô∏è G√©n√©ration de rapports d√©taill√©s  

---

## üîß Migration d'une Installation Existante

Si vous avez d√©j√† d√©ploy√© avec llama3:70b-instruct :

### √âtape 1 : Sauvegarder

```bash
# Sauvegarder la configuration actuelle
cp .env .env.backup.70b
cp config/rag_config.py config/rag_config.py.backup.70b
```

### √âtape 2 : Mettre √† jour

```bash
# Pull les derniers changements
git pull origin main

# Ou appliquer manuellement les changements
```

### √âtape 3 : Reconfigurer

```bash
# V√©rifier .env
grep "GEN_MODEL" .env

# Si n√©cessaire, mettre √† jour
sed -i 's/llama3:70b-instruct-2024-07-xx/llama3:8b-instruct/g' .env
sed -i 's/qwen2.5:14b-instruct/phi3:medium/g' .env
```

### √âtape 4 : Red√©ployer

```bash
# Arr√™ter les services
docker-compose -f docker-compose.hostinger.yml down

# Optionnel : Supprimer l'ancien mod√®le pour lib√©rer de l'espace
docker exec mcp-ollama ollama rm llama3:70b-instruct-2024-07-xx

# Red√©ployer avec le nouveau mod√®le
./deploy_rag_production.sh
```

---

## üìà M√©triques de Validation

### Apr√®s d√©ploiement, v√©rifier :

```bash
# 1. Temps de r√©ponse
time curl -X POST http://localhost:8000/api/v1/rag/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Test de performance", "node_pubkey": "feustey"}'

# Attendu : < 5s

# 2. RAM Ollama
docker stats mcp-ollama --no-stream

# Attendu : < 8 GB

# 3. Pr√©cision (test manuel)
# Comparer les r√©ponses avec des questions de r√©f√©rence
```

---

## üîÑ Rollback si N√©cessaire

Si la qualit√© est insuffisante, revenir au mod√®le 70B :

```bash
# 1. Restaurer la configuration
cp .env.backup.70b .env
cp config/rag_config.py.backup.70b config/rag_config.py

# 2. Red√©ployer
docker-compose -f docker-compose.hostinger.yml down
docker-compose -f docker-compose.hostinger.yml up -d --build

# 3. Pull le mod√®le 70B
docker exec mcp-ollama ollama pull llama3:70b-instruct-2024-07-xx
```

---

## üìû Support

Pour toute question sur ces changements :

1. Consulter `GUIDE_DEPLOIEMENT_RAG_LEGER.md`
2. V√©rifier les logs : `docker-compose logs -f`
3. Tester avec le fallback : `GEN_MODEL=phi3:medium`
4. R√©f√©rer √† la roadmap : `_SPECS/Roadmap-Production-v1.0.md`

---

**‚úÖ Changements appliqu√©s et valid√©s le 20 octobre 2025**


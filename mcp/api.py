# mcp/api.py\n\nimport time\nfrom fastapi import FastAPI, Query, HTTPException\nfrom pydantic import BaseModel, Field\nfrom typing import List, Dict, Optional, Set\nfrom datetime import datetime # Added import\n\n# Import our MCP modules\nfrom mcp import preprocessing\nfrom mcp import graph_analysis\nfrom mcp import node_scorer\nfrom mcp import candidate_selection\n# from . import lnbits_client # Placeholder for when available\n# from . import config_loader # Placeholder for config loading\n\n# --- Pydantic Models for API Request/Response ---\n\nclass SuggestionParams(BaseModel):\n    max_suggestions: int = Field(10, gt=0, description="Maximum number of suggestions to return.")\n    min_channel_size_sats: int = Field(20000, ge=0, description="Minimum channel size to suggest (sats).")\n    max_channel_size_sats: int = Field(10000000, ge=0, description="Maximum channel size to suggest (sats).")\n    budget_sats: Optional[int] = Field(None, ge=0, description="Total budget available for opening channels (sats).")\n    config_profile: str = Field("default", description="Name of the configuration profile to use (weights, lists).")\n    blocklist: Optional[List[str]] = Field(None, description="Additional node pubkeys to exclude.")\n    force_graph_refresh: bool = Field(False, description="Force refresh of graph data (if caching implemented).")\n\nclass HeuristicsBreakdown(BaseModel):\n    # Add specific scores if detailed breakdown is desired\n    # Example:\n    # capacity_score: Optional[float] = None\n    # centrality_score: Optional[float] = None # Sum of centrality heuristics\n    # channel_policy_score: Optional[float] = None # Sum of channel heuristics\n    pass # Keep empty for now unless detailed breakdown is implemented\n\nclass NodeSuggestion(BaseModel):\n    node_pubkey: str = Field(..., description="Public key of the suggested node.")\n    score: float = Field(..., description="Calculated overall score (higher is better).")\n    suggested_capacity_sats: int = Field(..., description="Suggested capacity for the channel (sats).")\n    addresses: List[str] = Field(default_factory=list, description="Known network addresses for the node.")\n    alias: Optional[str] = Field(None, description="Node alias, if known.")\n    # heuristics_breakdown: Optional[HeuristicsBreakdown] = None # Optional detailed scores\n\nclass SuggestionsResponse(BaseModel):\n    suggestions: List[NodeSuggestion]\n    analysis_timestamp: str = Field(..., description="ISO 8601 timestamp when the analysis was performed.")\n    config_profile_used: str = Field(..., description="Configuration profile name used for this analysis.")\n    notes: Optional[List[str]] = Field(default_factory=list, description="Any relevant notes or warnings from the process.")\n\n# --- FastAPI App ---\n\napp = FastAPI(\n    title="MCP API",\n    description="API for Lightning Network Channel Management Suggestions",\n    version="0.1.0",\n)\n\n# --- Placeholder Data & Config ---\n# Replace with actual config loading and LNBits client calls\n\nDEFAULT_WEIGHTS = {\n    "capacity": 1.0, "features": 0.5, "hybrid": 0.8,\n    "centrality": { "degree": 0.7, "betweenness": 1.5, "closeness": 0.6, "eigenvector": 1.2 },\n    "channels": { "base_fee": 0.5, "fee_rate": 0.8, "min_htlc": 0.3, "max_htlc": 0.6, "age": 0.9 }\n}\nDEFAULT_BLOCKLIST = ["BLOCKLISTED_NODE_FROM_CONFIG"]\n\n# Simulate LNBits Client / Data Source\ndef get_mock_graph_data():\n    print("--- MOCK: Fetching graph data ---")\n    # Structure mimicking LND DescribeGraph / expected format for preprocessing\n    mock_nodes = [\n        {\'pub_key\': \'A\', \'alias\': \'NodeA\', \'addresses\': [\'1.1.1.1:9735\'], \'features\': {1: {\'is_known\': True}}},\n        {\'pub_key\': \'B\', \'alias\': \'NodeB\', \'addresses\': [\'2.2.2.2:9735\', \'b.onion:9735\'], \'features\': {1: {\'is_known\': True}, 9:{\'is_known\': True}}},\n        {\'pub_key\': \'C\', \'alias\': \'NodeC\', \'addresses\': [\'3.3.3.3:9735\'], \'features\': {1: {\'is_known\': True}, 5:{\'is_known\': True}}},\n        {\'pub_key\': \'D\', \'alias\': \'NodeD\', \'addresses\': [\'4.4.4.4:9735\'], \'features\': {1: {\'is_known\': True}}},\n        {\'pub_key\': \'E\', \'alias\': \'NodeE\', \'addresses\': [\'e.onion:9735\'], \'features\': {1: {\'is_known\': True}, 7:{\'is_known\': True}}},\n        {\'pub_key\': \'F\', \'alias\': \'NodeF\', \'addresses\': [], \'features\': {1: {\'is_known\': True}}}, # No address\n        {\'pub_key\': \'G\', \'alias\': \'NodeG\', \'addresses\': [\'6.6.6.6:9735\'], \'features\': {}}, # Low capacity/channels implicitly\n        {\'pub_key\': \'HIGH_FEE_PEER\', \'alias\': \'HighFee\', \'addresses\': [\'7.7.7.7:9735\'], \'features\': {1: {\'is_known\': True}}},\n        {\'pub_key\': \'DISABLED_PEER\', \'alias\': \'Disabled\', \'addresses\': [\'8.8.8.8:9735\'], \'features\': {1: {\'is_known\': True}}},\n        {\'pub_key\': \'LOCAL_NODE_PUBKEY\', \'alias\': \'OurNode\', \'addresses\': [\'9.9.9.9:9735\'], \'features\': {1: {\'is_known\': True}}},\n    ]\n    mock_edges = [\n        {\'channel_id\': 800000 << 40 | 1 << 16 | 0, \'chan_point\': \'t:1:0\', \'capacity\': 5000000, \'node1_pub\': \'A\', \'node2_pub\': \'B\',\n         \'node1_policy\': {\'disabled\': False, \'fee_base_msat\': 100, \'fee_rate_milli_msat\': 50, \'min_htlc\': 1000, \'max_htlc_msat\': 4950000000},\n         \'node2_policy\': {\'disabled\': False, \'fee_base_msat\': 150, \'fee_rate_milli_msat\': 60, \'min_htlc\': 1000, \'max_htlc_msat\': 4950000000}},\n        {\'channel_id\': 800001 << 40 | 2 << 16 | 0, \'chan_point\': \'t:2:0\', \'capacity\': 2000000, \'node1_pub\': \'A\', \'node2_pub\': \'C\',\n         \'node1_policy\': {\'disabled\': False, \'fee_base_msat\': 50, \'fee_rate_milli_msat\': 20, \'min_htlc\': 500, \'max_htlc_msat\': 1980000000},\n         \'node2_policy\': {\'disabled\': False, \'fee_base_msat\': 60, \'fee_rate_milli_msat\': 30, \'min_htlc\': 500, \'max_htlc_msat\': 1980000000}},\n        {\'channel_id\': 750000 << 40 | 3 << 16 | 0, \'chan_point\': \'t:3:0\', \'capacity\': 10000000, \'node1_pub\': \'B\', \'node2_pub\': \'C\',\n         \'node1_policy\': {\'disabled\': False, \'fee_base_msat\': 200, \'fee_rate_milli_msat\': 100, \'min_htlc\': 1000, \'max_htlc_msat\': 9900000000},\n         \'node2_policy\': {\'disabled\': False, \'fee_base_msat\': 210, \'fee_rate_milli_msat\': 110, \'min_htlc\': 1000, \'max_htlc_msat\': 9900000000}},\n        {\'channel_id\': 805000 << 40 | 4 << 16 | 0, \'chan_point\': \'t:4:0\', \'capacity\': 8000000, \'node1_pub\': \'B\', \'node2_pub\': \'D\',\n         \'node1_policy\': {\'disabled\': False, \'fee_base_msat\': 80, \'fee_rate_milli_msat\': 80, \'min_htlc\': 1000, \'max_htlc_msat\': 7920000000},\n         \'node2_policy\': {\'disabled\': False, \'fee_base_msat\': 90, \'fee_rate_milli_msat\': 90, \'min_htlc\': 1000, \'max_htlc_msat\': 7920000000}},\n        {\'channel_id\': 780000 << 40 | 5 << 16 | 0, \'chan_point\': \'t:5:0\', \'capacity\': 3000000, \'node1_pub\': \'D\', \'node2_pub\': \'E\',\n         \'node1_policy\': {\'disabled\': False, \'fee_base_msat\': 30, \'fee_rate_milli_msat\': 30, \'min_htlc\': 1000, \'max_htlc_msat\': 2970000000},\n         \'node2_policy\': {\'disabled\': False, \'fee_base_msat\': 40, \'fee_rate_milli_msat\': 40, \'min_htlc\': 1000, \'max_htlc_msat\': 2970000000}},\n         {\'channel_id\': 810000 << 40 | 6 << 16 | 0, \'chan_point\': \'t:6:0\', \'capacity\': 1000000, \'node1_pub\': \'A\', \'node2_pub\': \'HIGH_FEE_PEER\',\n         \'node1_policy\': {\'disabled\': False, \'fee_base_msat\': 100, \'fee_rate_milli_msat\': 50, \'min_htlc\': 1000, \'max_htlc_msat\': 990000000},\n         \'node2_policy\': {\'disabled\': False, \'fee_base_msat\': 500000, \'fee_rate_milli_msat\': 5000, \'min_htlc\': 1000, \'max_htlc_msat\': 990000000}}, # High fees, node 2 policy should be discarded\n         {\'channel_id\': 700000 << 40 | 7 << 16 | 0, \'chan_point\': \'t:7:0\', \'capacity\': 1000000, \'node1_pub\': \'A\', \'node2_pub\': \'DISABLED_PEER\',\n         \'node1_policy\': {\'disabled\': False, \'fee_base_msat\': 100, \'fee_rate_milli_msat\': 50, \'min_htlc\': 1000, \'max_htlc_msat\': 990000000},\n         \'node2_policy\': {\'disabled\': True, \'fee_base_msat\': 10, \'fee_rate_milli_msat\': 10, \'min_htlc\': 1000, \'max_htlc_msat\': 990000000}}, # Disabled policy\n         {\'channel_id\': 600000 << 40 | 8 << 16 | 0, \'chan_point\': \'t:8:0\', \'capacity\': 500000, \'node1_pub\': \'A\', \'node2_pub\': \'LOCAL_NODE_PUBKEY\', # Channel with self\n         \'node1_policy\': {\'disabled\': False, \'fee_base_msat\': 100, \'fee_rate_milli_msat\': 50, \'min_htlc\': 1000, \'max_htlc_msat\': 495000000},\n         \'node2_policy\': {\'disabled\': False, \'fee_base_msat\': 150, \'fee_rate_milli_msat\': 60, \'min_htlc\': 1000, \'max_htlc_msat\': 495000000}},\n    ]\n    return mock_nodes, mock_edges\n\ndef get_mock_local_node_info():\n     print("--- MOCK: Fetching local node info ---")\n     return {\n        "pubkey": "LOCAL_NODE_PUBKEY",\n        "current_peers": {"EXISTING_PEER"}, # Peers we have channels with\n        "recent_closures": [\n            {"remote_pubkey": "CLOSED_RECENTLY", "close_height": 800000},\n        ]\n    }\n\ndef get_mock_current_block_height():\n    print("--- MOCK: Fetching current block height ---")\n    return 815000\n\n# --- API Endpoint ---\n\n@app.get(\n    "/api/v1/mcp/suggestions/open",\n    response_model=SuggestionsResponse,\n    summary="Get Node Suggestions for Opening Channels",\n    description="Analyzes the Lightning Network graph based on configured heuristics "\n                "and returns a ranked list of nodes to open channels with."\n)\nasync def get_open_suggestions(\n    max_suggestions: int = Query(10, gt=0, description="Maximum number of suggestions."),\n    min_channel_size_sats: int = Query(20000, ge=0, description="Minimum channel size (sats)."),\n    max_channel_size_sats: int = Query(10000000, ge=0, description="Maximum channel size (sats)."),\n    budget_sats: Optional[int] = Query(None, ge=0, description="Total budget available (sats)."),\n    config_profile: str = Query("default", description="Configuration profile name."),\n    blocklist_query: Optional[str] = Query(None, alias="blocklist", description="Comma-separated list of additional pubkeys to block."),\n    # force_graph_refresh: bool = Query(False, description="Force graph refresh."), # Parameter for later\n):\n    """\n    Provides suggestions for opening new Lightning Network channels.\n    """\n    process_start_time = time.time()\n    notes = []\n\n    # --- 1. Load Config (Placeholder) ---\n    print(f"Using config profile: {config_profile}")\n    weights = DEFAULT_WEIGHTS # Replace with config_loader logic\n    config_blocklist = DEFAULT_BLOCKLIST # Replace with config_loader logic\n    combined_blocklist = list(set(config_blocklist + (blocklist_query.split(\',\') if blocklist_query else [])))\n\n    # --- 2. Fetch Data (Mocked) ---\n    raw_nodes, raw_edges = get_mock_graph_data()\n    local_node_info = get_mock_local_node_info()\n    current_block_height = get_mock_current_block_height()\n\n    if not raw_nodes or not raw_edges:\n        notes.append("Warning: Could not fetch graph data.")\n        # Depending on requirements, could return empty list or raise error\n        # For now, return empty suggestion list.\n        return SuggestionsResponse(\n             suggestions=[],\n             analysis_timestamp=datetime.utcnow().isoformat() + "Z",\n             config_profile_used=config_profile,\n             notes=notes\n        )\n\n\n    # --- 3. Pre-processing ---\n    try:\n        channels_by_node, total_cap, valid_edges = preprocessing.filter_channels(raw_edges)\n        pre_filtered_nodes = preprocessing.pre_filter_nodes(raw_nodes, channels_by_node, total_cap, valid_edges)\n    except Exception as e:\n         print(f"Error during preprocessing: {e}")\n         raise HTTPException(status_code=500, detail=f"Preprocessing failed: {e}")\n\n    if not pre_filtered_nodes:\n         notes.append("No nodes passed the pre-filtering stage.")\n         return SuggestionsResponse(suggestions=[], analysis_timestamp=datetime.utcnow().isoformat() + "Z", config_profile_used=config_profile, notes=notes)\n\n\n    # --- 4. Graph Analysis & Centrality ---\n    try:\n        graph = graph_analysis.build_graph(pre_filtered_nodes)\n        # Ensure graph is not empty before calculating centralities\n        if graph.number_of_nodes() > 0:\n             centralities = graph_analysis.calculate_centralities(graph)\n        else:\n             centralities = {}\n             notes.append("Graph is empty after building; skipping centrality calculation.")\n\n    except Exception as e:\n         print(f"Error during graph analysis: {e}")\n         raise HTTPException(status_code=500, detail=f"Graph analysis failed: {e}")\n\n    # Enrich node data with centrality - create a list of nodes ready for scoring\n    nodes_to_score = []\n    for node_data in pre_filtered_nodes:\n         pubkey = node_data[\'pubkey\']\n         node_centrality = centralities.get(pubkey)\n         if node_centrality: # Only include nodes for which centrality was calculated\n             node_data[\'centrality\'] = node_centrality\n             nodes_to_score.append(node_data)\n         # else: # Log nodes excluded because they were filtered out before centrality or had no edges in filtered graph\n             # This happens naturally if a node\'s valid channels only connected to other filtered nodes\n             # notes.append(f"Warning: Node {pubkey[:10]}... missing from centrality results (likely isolated in filtered graph).")\n\n    if not nodes_to_score:\n         notes.append("No nodes available for scoring after centrality calculation.")\n         return SuggestionsResponse(suggestions=[], analysis_timestamp=datetime.utcnow().isoformat() + "Z", config_profile_used=config_profile, notes=notes)\n\n\n    # --- 5. Scoring ---\n    try:\n        scorer = node_scorer.NodeScorer(weights)\n        scorer.update_ranges(nodes_to_score) # Update ranges based *only* on nodes to be scored\n\n        scored_nodes = []\n        for node_data in nodes_to_score:\n             score = scorer.calculate_node_score(node_data)\n             node_data[\'score\'] = score\n             scored_nodes.append(node_data)\n\n        # Sort by score descending\n        scored_nodes.sort(key=lambda x: x.get(\'score\', 0.0), reverse=True)\n\n    except Exception as e:\n         print(f"Error during scoring: {e}")\n         raise HTTPException(status_code=500, detail=f"Scoring failed: {e}")\n\n    # --- 6. Final Candidate Selection ---\n    try:\n        final_candidates = candidate_selection.filter_candidates(\n            scored_nodes,\n            local_node_info,\n            combined_blocklist,\n            current_block_height\n        )\n    except Exception as e:\n         print(f"Error during final filtering: {e}")\n         raise HTTPException(status_code=500, detail=f"Final filtering failed: {e}")\n\n\n    # --- 7. Format Response ---\n    response_suggestions = []\n    # Simple capacity suggestion: average of min/max, respecting budget if provided\n    remaining_budget = budget_sats if budget_sats is not None else float(\'inf\')\n    num_suggestions_added = 0\n\n    for node in final_candidates:\n        if num_suggestions_added >= max_suggestions:\n            break\n\n        # Determine suggested capacity - simple logic for now\n        # Clamp suggestion between min/max bounds first\n        target_cap = int((min_channel_size_sats + max_channel_size_sats) / 2)\n        suggested_cap = max(min_channel_size_sats, min(target_cap, max_channel_size_sats))\n\n        if suggested_cap > remaining_budget:\n             # Try suggesting min size if budget allows, otherwise stop\n             if min_channel_size_sats <= remaining_budget and min_channel_size_sats > 0: # Ensure min is positive\n                  suggested_cap = min_channel_size_sats\n             else:\n                  continue # Cannot afford even min size, or min_size is 0\n\n        # Ensure suggested capacity is not zero if we have budget\n        if suggested_cap == 0 and remaining_budget > 0:\n             continue\n\n        response_suggestions.append(NodeSuggestion(\n            node_pubkey=node[\'pubkey\'],\n            score=node[\'score\'],\n            suggested_capacity_sats=suggested_cap,\n            addresses=node.get(\'addresses\', []),\n            alias=node.get(\'alias\')\n        ))\n        remaining_budget -= suggested_cap\n        num_suggestions_added += 1\n\n    process_end_time = time.time()\n    notes.append(f"Analysis completed in {process_end_time - process_start_time:.2f} seconds.")\n\n    return SuggestionsResponse(\n        suggestions=response_suggestions,\n        analysis_timestamp=datetime.utcnow().isoformat() + "Z",\n        config_profile_used=config_profile,\n        notes=notes\n    )\n\n# --- Main Execution (for running locally) ---\n# You would run this with: uvicorn mcp.api:app --reload\n# (Install uvicorn and fastapi first: pip install fastapi uvicorn[standard])\n# You also need: pip install networkx\n# Example: uvicorn mcp.api:app --reload --port 8001 